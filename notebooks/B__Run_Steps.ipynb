{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f563951a-d1b7-4e75-99f2-56be204cbc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff402f6b-df30-4f99-8742-1881c7e2e6b9",
   "metadata": {},
   "source": [
    "This is a notebook that illustrates how to run the end-to-end (e2e) workflow. Determining suitable parameters for the workflow are for operational considerations are explained in the ops library [`dist-s1-enumerator`](https://github.com/opera-adt/dist-s1-enumerator) - specifically, see this [notebook](https://github.com/opera-adt/dist-s1-enumerator/blob/dev/notebooks/A__Staging_Inputs_for_One_MGRS_Tile.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91fb3320-c91c-465c-9ac3-926076e413e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cmarshak/miniforge3/envs/dist-s1-env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from dist_s1.workflows import (\n",
    "    run_burst_disturbance_workflow,\n",
    "    run_dist_s1_localization_workflow,\n",
    "    run_dist_s1_workflow,\n",
    "    run_disturbance_merge_workflow,\n",
    "    run_dist_s1_packaging_workflow,\n",
    "    run_despeckle_workflow\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ce1f145-b58c-4982-b256-6a56b552d4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example 0\n",
    "\n",
    "# mgrs_tile_id = '10SGD'\n",
    "# post_date = '2025-01-02'\n",
    "# track_number = 137\n",
    "# dst_dir = Path('out')\n",
    "# memory_strategy = 'high'\n",
    "\n",
    "\n",
    "## Example 1 - Los Angeles Wildfire\n",
    "mgrs_tile_id = '11SLT'\n",
    "post_date = '2025-01-21'\n",
    "track_number = 71\n",
    "dst_dir = Path('los-angeles')\n",
    "memory_strategy = 'high'\n",
    "confirmation = False\n",
    "interpolation_method='bilinear'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f264fe-f74c-4d3f-b492-27902eaed32e",
   "metadata": {},
   "source": [
    "This takes some time as it not only generates the runconfig but also localizes the necessary data. It will not overwrite files that have been previously downloaded.\n",
    "\n",
    "Few additional notes:\n",
    "\n",
    "1. The runconfig can be serialized to yml and then read from that file.\n",
    "2. The runconfig manages all the paths for the workflows from the initial set of inputs. It's data model is messy and can be confusing. But that's the workhorse of this library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7ee7ad2-b297-41af-bc65-e41cf40dab1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using multi-window lookback strategy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading RTC-S1 burst data: 100%|█| 352/352 [00:00<00:00,\n",
      "/Users/cmarshak/bekaert-team/dist-s1/src/dist_s1/data_models/runconfig_model.py:599: UserWarning: CUDA and mps do not support multiprocessing; setting n_workers_for_norm_param_estimation to 1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "run_config = run_dist_s1_localization_workflow(\n",
    "    mgrs_tile_id,\n",
    "    post_date,\n",
    "    track_number,\n",
    "    post_date_buffer_days=1,\n",
    "    dst_dir=dst_dir,\n",
    "    input_data_dir=dst_dir,\n",
    "    confirmation=confirmation,\n",
    "    interpolation_method='bilinear',\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55f54f84-fe2e-446b-b8f0-ddb894b10f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Despeckling and serializing RTC S1 files: 100%|█| 352/352 [0\n"
     ]
    }
   ],
   "source": [
    "if run_config.apply_despeckling:\n",
    "    run_despeckle_workflow(run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ad989d5-b3a5-4e50-93fb-e32812f3d97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Burst disturbance:   0%|             | 0/16 [00:00<?, ?it/s]\n",
      "Chips Traversed:   0%|              | 0/656 [00:00<?, ?it/s]\u001b[A\n",
      "Chips Traversed: 100%|███| 656/656 [00:03<00:00, 216.70it/s]\u001b[A\n",
      "/Users/cmarshak/miniforge3/envs/dist-s1-env/lib/python3.13/site-packages/torch/nn/functional.py:5561: UserWarning: The operator 'aten::col2im' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/miniforge3/conda-bld/libtorch_1746257056484/work/aten/src/ATen/mps/MPSFallback.mm:14.)\n",
      "  return torch._C._nn.col2im(\n",
      "/Users/cmarshak/bekaert-team/dist-s1/src/dist_s1/processing.py:127: RuntimeWarning: All-NaN slice encountered\n",
      "  metric = np.nanmax(z_score_per_channel, axis=0)\n",
      "Burst disturbance:   6%|▎    | 1/16 [00:05<01:18,  5.26s/it]\n",
      "Chips Traversed: 100%|███| 586/586 [00:01<00:00, 314.39it/s]\u001b[A\n",
      "Burst disturbance:  12%|▋    | 2/16 [00:08<00:59,  4.26s/it]\n",
      "Chips Traversed: 100%|███| 659/659 [00:01<00:00, 333.23it/s]\u001b[A\n",
      "Burst disturbance:  19%|▉    | 3/16 [00:12<00:54,  4.21s/it]\n",
      "Chips Traversed: 100%|███| 586/586 [00:01<00:00, 390.88it/s]\u001b[A\n",
      "Burst disturbance:  25%|█▎   | 4/16 [00:16<00:45,  3.78s/it]\n",
      "Chips Traversed: 100%|███| 656/656 [00:01<00:00, 397.08it/s]\u001b[A\n",
      "Burst disturbance:  31%|█▌   | 5/16 [00:19<00:41,  3.79s/it]\n",
      "Chips Traversed: 100%|███| 586/586 [00:01<00:00, 319.12it/s]\u001b[A\n",
      "Burst disturbance:  38%|█▉   | 6/16 [00:23<00:37,  3.72s/it]\n",
      "Chips Traversed: 100%|███| 656/656 [00:01<00:00, 387.79it/s]\u001b[A\n",
      "Burst disturbance:  44%|██▏  | 7/16 [00:27<00:33,  3.77s/it]\n",
      "Chips Traversed: 100%|███| 586/586 [00:01<00:00, 392.31it/s]\u001b[A\n",
      "Burst disturbance:  50%|██▌  | 8/16 [00:30<00:29,  3.65s/it]\n",
      "Chips Traversed:   0%|              | 0/663 [00:00<?, ?it/s]\u001b[A\n",
      "Chips Traversed: 100%|███| 663/663 [00:02<00:00, 307.23it/s]\u001b[A\n",
      "Burst disturbance:  56%|██▊  | 9/16 [00:35<00:26,  3.85s/it]\n",
      "Chips Traversed: 100%|███| 586/586 [00:01<00:00, 399.74it/s]\u001b[A\n",
      "Burst disturbance:  62%|██▌ | 10/16 [00:38<00:21,  3.66s/it]\n",
      "Chips Traversed: 100%|███| 663/663 [00:01<00:00, 364.07it/s]\u001b[A\n",
      "Burst disturbance:  69%|██▊ | 11/16 [00:42<00:18,  3.77s/it]\n",
      "Chips Traversed: 100%|███| 586/586 [00:01<00:00, 346.23it/s]\u001b[A\n",
      "Burst disturbance:  75%|███ | 12/16 [00:45<00:14,  3.68s/it]\n",
      "Chips Traversed: 100%|███| 663/663 [00:01<00:00, 395.84it/s]\u001b[A\n",
      "Burst disturbance:  81%|███▎| 13/16 [00:49<00:11,  3.81s/it]\n",
      "Chips Traversed: 100%|███| 586/586 [00:01<00:00, 375.60it/s]\u001b[A\n",
      "Burst disturbance:  88%|███▌| 14/16 [00:53<00:07,  3.66s/it]\n",
      "Chips Traversed: 100%|███| 663/663 [00:01<00:00, 353.83it/s]\u001b[A\n",
      "Burst disturbance:  94%|███▊| 15/16 [00:56<00:03,  3.70s/it]\n",
      "Chips Traversed: 100%|███| 586/586 [00:01<00:00, 375.57it/s]\u001b[A\n",
      "Burst disturbance: 100%|████| 16/16 [01:00<00:00,  3.76s/it]\n"
     ]
    }
   ],
   "source": [
    "# Compute disturbance per burst and all possible lookbacks\n",
    "run_burst_disturbance_workflow(run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b9aa7a-1fab-44ea-b760-9dce254c2fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the burst-wise products\n",
    "run_disturbance_merge_workflow(run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a255865-caa4-4958-92b4-2d439d8cadac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No confirmation requested, skipping confirmation step\n"
     ]
    },
    {
     "ename": "RasterioIOError",
     "evalue": "/Users/cmarshak/bekaert-team/dist-s1/notebooks/los-angeles/OPERA_L3_DIST-ALERT-S1_T11SLT_20250121T135246Z_20250714T115920Z_S1_30_v0.1/OPERA_L3_DIST-ALERT-S1_T11SLT_20250121T135246Z_20250714T115920Z_S1_30_v0.1_GEN-METRIC-MAX.tif: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCPLE_OpenFailedError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mrasterio/_base.pyx:310\u001b[39m, in \u001b[36mrasterio._base.DatasetBase.__init__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mrasterio/_base.pyx:221\u001b[39m, in \u001b[36mrasterio._base.open_dataset\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mrasterio/_err.pyx:359\u001b[39m, in \u001b[36mrasterio._err.exc_wrap_pointer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mCPLE_OpenFailedError\u001b[39m: /Users/cmarshak/bekaert-team/dist-s1/notebooks/los-angeles/OPERA_L3_DIST-ALERT-S1_T11SLT_20250121T135246Z_20250714T115920Z_S1_30_v0.1/OPERA_L3_DIST-ALERT-S1_T11SLT_20250121T135246Z_20250714T115920Z_S1_30_v0.1_GEN-METRIC-MAX.tif: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRasterioIOError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrun_dist_s1_packaging_workflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bekaert-team/dist-s1/src/dist_s1/workflows.py:242\u001b[39m, in \u001b[36mrun_dist_s1_packaging_workflow\u001b[39m\u001b[34m(run_config)\u001b[39m\n\u001b[32m    239\u001b[39m     package_conf_db_disturbance_tifs(run_config)\n\u001b[32m    241\u001b[39m product_data = run_config.product_data_model\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m \u001b[43mproduct_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_conf_db_tif_layer_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    243\u001b[39m product_data.validate_conf_db_layer_paths()\n\u001b[32m    245\u001b[39m generate_browse_image(run_config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bekaert-team/dist-s1/src/dist_s1/data_models/output_models.py:254\u001b[39m, in \u001b[36mProductDirectoryData.validate_conf_db_tif_layer_dtypes\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    252\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m path.suffix == \u001b[33m'\u001b[39m\u001b[33m.tif\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mrasterio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m src:\n\u001b[32m    255\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m src.dtypes[\u001b[32m0\u001b[39m] != TIF_LAYER_DTYPES[layer]:\n\u001b[32m    256\u001b[39m             warn(\n\u001b[32m    257\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mLayer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m has incorrect dtype: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc.dtypes[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m; should be: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTIF_LAYER_DTYPES[layer]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m    258\u001b[39m                 \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    259\u001b[39m             )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/dist-s1-env/lib/python3.13/site-packages/rasterio/env.py:463\u001b[39m, in \u001b[36mensure_env_with_credentials.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m    460\u001b[39m     session = DummySession()\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m env_ctor(session=session):\n\u001b[32m--> \u001b[39m\u001b[32m463\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/dist-s1-env/lib/python3.13/site-packages/rasterio/__init__.py:356\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, opener, **kwargs)\u001b[39m\n\u001b[32m    353\u001b[39m     path = _parse_path(raw_dataset_path)\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m     dataset = \u001b[43mDatasetReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharing\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mr+\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    358\u001b[39m     dataset = get_writer_for_path(path, driver=driver)(\n\u001b[32m    359\u001b[39m         path, mode, driver=driver, sharing=sharing, **kwargs\n\u001b[32m    360\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mrasterio/_base.pyx:312\u001b[39m, in \u001b[36mrasterio._base.DatasetBase.__init__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mRasterioIOError\u001b[39m: /Users/cmarshak/bekaert-team/dist-s1/notebooks/los-angeles/OPERA_L3_DIST-ALERT-S1_T11SLT_20250121T135246Z_20250714T115920Z_S1_30_v0.1/OPERA_L3_DIST-ALERT-S1_T11SLT_20250121T135246Z_20250714T115920Z_S1_30_v0.1_GEN-METRIC-MAX.tif: No such file or directory"
     ]
    }
   ],
   "source": [
    "run_dist_s1_packaging_workflow(run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda8509a-835c-460d-b31d-2fc44b56ca83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dist-s1-env",
   "language": "python",
   "name": "dist-s1-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
